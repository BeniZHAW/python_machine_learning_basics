{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object detection with Python and tensorflow\n",
    "\n",
    "For details (including installation instructions) see: https://www.mygreatlearning.com/blog/object-detection-using-tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://blog.jetbrains.com/wp-content/uploads/2022/01/dog.jpg\" alt=\"\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c721842a-a1b5-4c83-b3a4-8fbdcf857e02",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'string_int_label_map_pb2' from 'object_detection.protos' (c:\\Users\\gell\\AppData\\Local\\anaconda3\\envs\\mlenv\\Lib\\site-packages\\object_detection\\protos\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mobject_detection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops \u001b[38;5;28;01mas\u001b[39;00m utils_ops\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mobject_detection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m label_map_util\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mobject_detection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m visualization_utils \u001b[38;5;28;01mas\u001b[39;00m vis_util\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Set path\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gell\\AppData\\Local\\anaconda3\\envs\\mlenv\\Lib\\site-packages\\object_detection\\utils\\label_map_util.py:21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m text_format\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mobject_detection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotos\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m string_int_label_map_pb2\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_label_map\u001b[39m(label_map):\n\u001b[0;32m     25\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Checks if a label map is valid.\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m    ValueError: if label map is invalid.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'string_int_label_map_pb2' from 'object_detection.protos' (c:\\Users\\gell\\AppData\\Local\\anaconda3\\envs\\mlenv\\Lib\\site-packages\\object_detection\\protos\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "# Set path\n",
    "while \"models\" in pathlib.Path.cwd().parts:\n",
    "    os.chdir('..')\n",
    "\n",
    "# Supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Get current working directory\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4193429-c942-4193-a4d7-02936ae814a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "  base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
    "  model_file = model_name + '.tar.gz'\n",
    "  model_dir = tf.keras.utils.get_file(\n",
    "    fname=model_name, \n",
    "    origin=base_url + model_file,\n",
    "    untar=True)\n",
    " \n",
    "  model_dir = pathlib.Path(model_dir)/\"saved_model\"\n",
    "  model = tf.saved_model.load(str(model_dir))\n",
    "  \n",
    "  return model\n",
    "\n",
    "def run_inference_for_single_image(model, image):\n",
    "  image = np.asarray(image)\n",
    "  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "  input_tensor = tf.convert_to_tensor(image)\n",
    "  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "  input_tensor = input_tensor[tf.newaxis,...]\n",
    " \n",
    "  # Run inference\n",
    "  model_fn = model.signatures['serving_default']\n",
    "  output_dict = model_fn(input_tensor)\n",
    " \n",
    "  # All outputs are batches tensors.\n",
    "  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "  # We're only interested in the first num_detections.\n",
    "  num_detections = int(output_dict.pop('num_detections'))\n",
    "  output_dict = {key:value[0, :num_detections].numpy() \n",
    "                 for key,value in output_dict.items()}\n",
    "  output_dict['num_detections'] = num_detections\n",
    " \n",
    "  # detection_classes should be ints.\n",
    "  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
    "\n",
    "  # Handle models with masks:\n",
    "  if 'detection_masks' in output_dict:\n",
    "    # Reframe the the bbox mask to the image size.\n",
    "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "              output_dict['detection_masks'], output_dict['detection_boxes'],\n",
    "               image.shape[0], image.shape[1])      \n",
    "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
    "                                       tf.uint8)\n",
    "    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
    "     \n",
    "  return output_dict\n",
    "\n",
    "def show_inference_image(model, image_path):\n",
    "  # The array based representation of the image will be used later \n",
    "  # in order to prepare the result image with boxes and labels on it.\n",
    "  image_np = np.array(Image.open(image_path))\n",
    "\n",
    "  # Actual detection\n",
    "  output_dict = run_inference_for_single_image(model, image_np)\n",
    "\n",
    "  # Visualization of the results of a detection.\n",
    "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np,\n",
    "      output_dict['detection_boxes'],\n",
    "      output_dict['detection_classes'],\n",
    "      output_dict['detection_scores'],\n",
    "      category_index,\n",
    "      instance_masks=output_dict.get('detection_masks_reframed', None),\n",
    "      use_normalized_coordinates=True,\n",
    "      line_thickness=4)\n",
    "\n",
    "  display(Image.fromarray(image_np))\n",
    "\n",
    "def show_inference_webcam_feed(model, frame):\n",
    "  # Take frame from webcam feed and convert to array\n",
    "  image_np = np.array(frame)\n",
    "  \n",
    "  # Actual detection\n",
    "  output_dict = run_inference_for_single_image(model, image_np)\n",
    "  \n",
    "  # Visualization of the results of a detection\n",
    "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np,\n",
    "      output_dict['detection_boxes'],\n",
    "      output_dict['detection_classes'],\n",
    "      output_dict['detection_scores'],\n",
    "      category_index,\n",
    "      instance_masks=output_dict.get('detection_masks_reframed', None),\n",
    "      use_normalized_coordinates=True,\n",
    "      line_thickness=4)\n",
    " \n",
    "  return(image_np)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path to labels and pre-trained object detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'label_map_util' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Path to labels\u001b[39;00m\n\u001b[0;32m      2\u001b[0m PATH_TO_LABELS \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/research/object_detection/data/mscoco_label_map.pbtxt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m category_index \u001b[38;5;241m=\u001b[39m \u001b[43mlabel_map_util\u001b[49m\u001b[38;5;241m.\u001b[39mcreate_category_index_from_labelmap(PATH_TO_LABELS, use_display_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Pre-trained object detection model\u001b[39;00m\n\u001b[0;32m      6\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mssd_inception_v2_coco_2017_11_17\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'label_map_util' is not defined"
     ]
    }
   ],
   "source": [
    "# Path to labels\n",
    "PATH_TO_LABELS = 'models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n",
    "\n",
    "# Pre-trained object detection model\n",
    "model_name = 'ssd_inception_v2_coco_2017_11_17'\n",
    "detection_model = load_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting objects on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to images\n",
    "PATH_TO_TEST_IMAGES_DIR = pathlib.Path('models/research/object_detection/test_images')\n",
    "TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob(\"*.jpg\")))\n",
    "\n",
    "# Show object classification\n",
    "for image_path in TEST_IMAGE_PATHS:\n",
    "    print(image_path)\n",
    "    show_inference_image(detection_model, image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting objects in real time using a webcam feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7e2516-9965-4dee-a58d-4a38c35586a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pre-trained model\n",
    "model_name = 'ssd_inception_v2_coco_2017_11_17'\n",
    "detection_model = load_model(model_name)\n",
    "\n",
    "# Open webcam and start detecting objects\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    re,frame = video_capture.read()\n",
    "    Imagenp=show_inference_webcam_feed(detection_model, frame)\n",
    "    cv2.imshow('object detection', cv2.resize(Imagenp, (800,600)))\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter notebook --footer info-- (please always provide this at the end of each submitted notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "import socket\n",
    "from platform import python_version\n",
    "from datetime import datetime\n",
    "\n",
    "print('-----------------------------------')\n",
    "print(os.name.upper())\n",
    "print(platform.system(), '|', platform.release())\n",
    "print('Datetime:', datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print('Python Version:', python_version())\n",
    "print('-----------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
