{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster the Olivetti Faces Dataset with K-Means\n",
    "\n",
    "(Notebook adapted from: A.Geron, Hands On ML with Scikit-Learn, Keras und Tensorflow, O'Reilly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this week exercise we will try to cluster human pictures, in order to identify which picture belong to the same subject/person. \n",
    "We will use an unsupervised learning approach, which means we will train without knowing the correct assignment of the pictures (in other words the person have no labels).\n",
    "As usual, answer the questions/comments and add your code where indicated. Otherwise just try to understand what's happening :-).\n",
    "\n",
    "About the database: The classic Olivetti faces dataset contains 400 grayscale 64 × 64–pixel images of faces. Each image is flattened to a 1D vector of size 4,096. 40 different people were photographed (10 times each). Load the dataset using the `sklearn.datasets.fetch_olivetti_faces()` function.\n",
    "For some subjects, the images were taken at different times, varying the lighting, facial expressions (open / closed eyes, smiling / not smiling) and facial details (glasses / no glasses). All the images were taken against a dark\n",
    "homogeneous background with the subjects in an upright, frontal position (with tolerance for some side movement)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "\n",
    "# Settings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Show current working directory\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "olivetti = fetch_olivetti_faces()\n",
    "\n",
    "# Show data description\n",
    "# print(olivetti.DESCR) \n",
    "\n",
    "# Data matrix\n",
    "X = olivetti.data\n",
    "\n",
    "# Data shape (nrows, ncols)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the images are 64x64pixels, the number of features (=number of total pixels) is 4096. This a huge number of variables to check out for clustering. So, for convenience we should first try to see if we can reduce the number of features we feed to k-means. This operation is called \"Dimensionality Reduction\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PCA to reduce the dimensionality of the data\n",
    "pca = PCA(0.99)\n",
    "\n",
    "# Fit the PCA model to the data\n",
    "X_pca = pca.fit_transform(olivetti.data)\n",
    "\n",
    "# Check the number of components\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform k-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done :) we reduce dimensionality quite a lot!\n",
    "\n",
    "Let's now perform k-means on this subset of features: X_pca  \n",
    "\n",
    "Use the function https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html and the advices given in the class.  \n",
    "\n",
    "Remember that you have to define the number of clusters k.\n",
    "\n",
    "How to set k? Start with a \"reasonable\" guess and qualitatively look how good the clustering is. \n",
    "\n",
    "Try to change k manually and see if it improves or get worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=5, random_state=42) ### ADD YOUR CODE HERE ###\n",
    "kmeans.fit(X_pca)\n",
    "\n",
    "def plot_faces(faces, n_cols=5):\n",
    "    n_rows = (len(faces) - 1) // n_cols + 1\n",
    "    plt.figure(figsize=(n_cols, n_rows * 1.1))\n",
    "    for index, face in enumerate(faces):\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(face.reshape(64, 64), cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "for cluster_id in np.unique(kmeans.labels_):\n",
    "    print(\"Cluster\", cluster_id)\n",
    "    in_cluster = kmeans.labels_==cluster_id\n",
    "    faces = X[in_cluster].reshape(-1, 64, 64)\n",
    "    plot_faces(faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was your best k?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a loop to identify the best k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a serious approach we should try to identify K through a more robust approach. \n",
    "Let's run the k-means algorithm in a loop, every time with a different number of clusters, K. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Feel free to change the range limits or step\n",
    "k_range = range(5, 150, 5)\n",
    "kmeans_per_k = []\n",
    "for k in k_range:\n",
    "    print(\"k={}\".format(k))\n",
    "    kmeans = KMeans(n_clusters=k)  ### ADD YOUR CODE HERE ###\n",
    "    kmeans.fit(X_pca)\n",
    "    kmeans_per_k.append(kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Intertia (Within-Cluster Sum of Squares, WCSS)  for each run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now evaluate for each of this run the inertia of the model. Luckily, this is part of the Sklearn KMeans function's output (Z.B. kmeans.inertia_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertias = [model.inertia_ for model in kmeans_per_k]\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(k_range, inertias, \"bo-\")\n",
    "plt.xlabel(\"$k$\", fontsize=14)\n",
    "plt.ylabel(\"Inertia\", fontsize=14)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you get from this plot a clear indication on what could be a good value for k?  \n",
    "\n",
    "Do you see an \"elbow\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate silhouette score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with the more sophisticated method called silhouette analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "silhouette_scores = [silhouette_score(X_pca, model.labels_) for model in kmeans_per_k]\n",
    "best_index = np.argmax(silhouette_scores)\n",
    "best_k = k_range[best_index]\n",
    "best_score = silhouette_scores[best_index]\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(k_range, silhouette_scores, \"bo-\")\n",
    "plt.xlabel(\"$k$\", fontsize=14)\n",
    "plt.ylabel(\"Silhouette score\", fontsize=14)\n",
    "plt.plot(best_k, best_score, \"rs\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the best value for k according to this method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The best k is: {best_k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the best number of clusters is quite high. \n",
    "How does it compare with your first reasonable guess? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a direct look of how pictures are grouped according to the best k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters = 140) ### ADD VALUE OF BEST K HERE ###\n",
    "kmeans.fit(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_faces(faces, n_cols=5):\n",
    "    n_rows = (len(faces) - 1) // n_cols + 1\n",
    "    plt.figure(figsize=(n_cols, n_rows * 1.1))\n",
    "    for index, face in enumerate(faces):\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(face.reshape(64, 64), cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "for cluster_id in np.unique(kmeans.labels_):\n",
    "    print(\"Cluster\", cluster_id)\n",
    "    in_cluster = kmeans.labels_==cluster_id\n",
    "    faces = X[in_cluster].reshape(-1, 64, 64)\n",
    "    plot_faces(faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter notebook --footer info-- (please always provide this at the end of each notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "import socket\n",
    "from platform import python_version\n",
    "from datetime import datetime\n",
    "\n",
    "print('-----------------------------------')\n",
    "print(os.name.upper())\n",
    "print(platform.system(), '|', platform.release())\n",
    "print('Datetime:', datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print('Python Version:', python_version())\n",
    "print('-----------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
